name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  test:
    name: Test Python ${{ matrix.python-version }}
    runs-on: ${{ matrix.os }}
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        python-version: ['3.10', '3.11', '3.12']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install uv
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
    
    - name: Install dependencies
      run: |
        uv sync
    
    - name: Run linter
      run: |
        uv run ruff check src/ tests/
    
    - name: Run type checker
      run: |
        uv run mypy src/ --ignore-missing-imports
      continue-on-error: true
    
    - name: Run tests with coverage
      run: |
        uv run pytest --cov=src --cov-report=xml --cov-report=term-missing --cov-fail-under=80 -v
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        fail_ci_if_error: false
    
    - name: Check coverage threshold
      run: |
        uv run coverage report --fail-under=85

  performance:
    name: Performance Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.11'
    
    - name: Install uv
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
    
    - name: Install dependencies
      run: |
        uv sync
    
    # Performance tests focus on speed, not code coverage
    - name: Run performance tests
      run: |
        uv run pytest tests/test_performance_comprehensive.py -v --durations=10 --no-cov
    
    - name: Performance benchmark
      run: |
        uv run pytest tests/test_performance_comprehensive.py --benchmark-only --benchmark-json=benchmark.json --no-cov
      continue-on-error: true

  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.11'
    
    - name: Install uv
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
    
    - name: Install dependencies
      run: |
        uv sync
    
    # Integration tests focus on workflows, not code coverage
    # Coverage is measured in the main test job which runs ALL tests
    - name: Run integration tests
      run: |
        uv run pytest tests/test_integration*.py tests/test_complete_game_flow.py tests/test_functional_real_flow.py -v --no-cov
    
    - name: Test full league flow
      run: |
        uv run pytest tests/launcher/test_integration_modular_flow.py -v --no-cov

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Run Bandit security scan
      run: |
        pip install bandit
        bandit -r src/ -f json -o bandit-report.json
      continue-on-error: true
    
    - name: Run Safety check
      run: |
        pip install safety
        safety check
      continue-on-error: true

  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.11'
    
    - name: Install uv
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
    
    - name: Install dependencies
      run: |
        uv sync
    
    - name: Check code formatting
      run: |
        uv run black --check src/ tests/
      continue-on-error: true
    
    - name: Check import sorting
      run: |
        uv run isort --check-only src/ tests/
      continue-on-error: true
    
    - name: Run complexity analysis
      run: |
        uv run radon cc src/ -a -nb
      continue-on-error: true
    
    - name: Generate coverage badge
      run: |
        uv run coverage-badge -o coverage.svg
      continue-on-error: true

